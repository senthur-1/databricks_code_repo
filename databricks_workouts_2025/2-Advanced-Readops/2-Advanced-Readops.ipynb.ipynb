{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ba054dd-d731-41a9-a3a4-4607f6fc8d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Try to use this sales data with atleast very important and important options...\n",
    "https://drive.google.com/file/d/1MZI4XIofL-0QpMIr9sFODSKVkexrSZ1A/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b6b7fb3-a14f-4146-a1f7-544bc984250a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###1. CSV Advanced Features - \n",
    "######Very Important - path: PathOrPaths, schema: Optional[Union[StructType, str]]=None, sep: Optional[str]=None,header: Optional[Union[bool, str]]=None, inferSchema: Optional[Union[bool, str]]=None, \n",
    "######Important - mode: Optional[str]=None, columnNameOfCorruptRecord: Optional[str]=None,  quote: Optional[str]=None, escape: Optional[str]=None, \n",
    "Not Important but good to know once - encoding: Optional[str]=None, comment: Optional[str]=None,ignoreLeadingWhiteSpace: Optional[Union[bool, str]]=None, ignoreTrailingWhiteSpace: Optional[Union[bool, str]]=None, nullValue: Optional[str]=None, nanValue: Optional[str]=None, positiveInf: Optional[str]=None, negativeInf: Optional[str]=None, dateFormat: Optional[str]=None, timestampFormat: Optional[str]=None, maxColumns: Optional[Union[int, str]]=None, maxCharsPerColumn: Optional[Union[int, str]]=None, maxMalformedLogPerPartition: Optional[Union[int, str]]=None,   multiLine: Optional[Union[bool, str]]=None, charToEscapeQuoteEscaping: Optional[str]=None, samplingRatio: Optional[Union[float, str]]=None, enforceSchema: Optional[Union[bool, str]]=None, emptyValue: Optional[str]=None, locale: Optional[str]=None, lineSep: Optional[str]=None, pathGlobFilter: Optional[Union[bool, str]]=None, recursiveFileLookup: Optional[Union[bool, str]]=None, modifiedBefore: Optional[Union[bool, str]]=None, modifiedAfter: Optional[Union[bool, str]]=None, unescapedQuoteHandling: Optional[str]=None) -> \"DataFrame\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a084f7-6702-4345-9397-002efd0188c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### A. Options for handling quotes & Escape\n",
    "\n",
    "id,name,remarks\n",
    "1,'Ramesh, K.P','Good performer'\n",
    "2,'Manoj','Needs ~'special~' attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "118bad05-cf08-4cc0-888d-59ec28923cb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#When to go for quote: If the data is having delimiter in it..\n",
    "#When to go for escape: If the data is having quote in it...\n",
    "struct1=\"custid int,name string,age int,corrupt_record string\"\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/workspace/default/volumewd36/malformeddata1.txt\",header=False,sep=',',mode='permissive',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote=\"'\",escape=\"|\")\n",
    "df1.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5fa1bb6-03cd-4959-9796-dc4291b34c97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### B. Comments, Multi line, leading and trailing whitespace handling, null and nan handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e4f14cb-4ad8-46e4-98ce-e02b44d1819b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "struct1=\"custid int,name string,height float,joindt date,age string\"\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/workspace/default/volumewd36/malformeddata2.txt\",header=False,mode='permissive'\n",
    "                                   ,multiLine=True,quote=\"'\",ignoreLeadingWhiteSpace=True,ignoreTrailingWhiteSpace=True,\n",
    "                                   nullValue='na',nanValue=-1,maxCharsPerColumn='100',modifiedAfter='2025-12-19',dateFormat=\"yyyy-dd-MM\")\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f869d72-8ad6-48be-9ebf-130bd2663228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### C. Read modes in csv (Important feature)\n",
    "If any data challenges (malformed data) such as format issue/column numbers (lesser/more than expected) issue etc.,\n",
    "### There are 3 typical read modes and the default read mode is permissive.\n",
    "##### 1. permissive — All fields are set to null and corrupted records are placed in a string column called _corrupt_record\n",
    "##### \t2. dropMalformed — Drops all rows containing corrupt records.\n",
    "##### 3. failFast — Fails when corrupt records are encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35811751-4ac5-45d0-a977-f20d85ae7e6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We learned about few important features mode, columnNameOfCorruptRecord, Quote, Comment\n",
    "#Question - Corrupt_record column consume more memory because it capturing all the column values(incorrect) in one column. ? Useful for doing RCA (Root Cause Analysis/Debugging)\n",
    "struct1=\"custid int,name string,age int,corrupt_record string\"\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/workspace/default/volumewd36/malformeddata.txt\",header=False,sep=',',mode='permissive',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote=\"'\")\n",
    "df1.show(10)\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/workspace/default/volumewd36/malformeddata.txt\",header=False,sep=',',mode='dropMalformed',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote=\"'\")\n",
    "df1.show(10)\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/workspace/default/volumewd36/malformeddata.txt\",header=False,sep=',',mode='failFast',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote=\"'\")\n",
    "df1.show(10)\n",
    "#df1.filter(\"corrupt_record is not null\").write.csv(\"/Volumes/workspace/default/volumewd36/rejecteddata\")\n",
    "#spark.read.csv(\"/Volumes/workspace/default/volumewd36/rejecteddata\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a8a54d6-8e02-4a5c-87ef-bd1d07bc07d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2-Advanced-Readops.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
